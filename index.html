<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="google-site-verification" content="x-tyvWZv6HwbgJL_crBVvGDUNeEBNQy2psvddHP8oa4" />

  <title>Itamar Pres</title>
  <meta name="description" content="Personal website of Itamar Pres">

  <link rel="canonical" href="https://itam67.github.io/" />
  <meta property="og:title" content="Itamar Pres | MIT PhD Student">
  <meta property="og:description" content="MIT EECS PhD student working on AI safety">
  <meta property="og:url" content="https://itam67.github.io/" />
  <meta property="og:image" content="https://itam67.github.io/images/headshot.png" />

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <h1>Itamar Hagay Pres</h1>

                  </p>

                  <!-- Description -->
                  <p>I'm a PhD student at MIT, where I work with <a href="https://www.mit.edu/~jda/">Jacob Andreas</a> in the <a href="https://lingo.csail.mit.edu/">Language and Intelligence Group</a> at <a href="https://www.csail.mit.edu">CSAIL</a>.
                     My primary focus is on making artificial intelligence systems safer, more interpretable, and better
                    aligned with human values.
                  </p>
          

                  <p>At Michigan, I was involved with the <a href="https://lit.eecs.umich.edu/">Language and Information Technologies Lab</a>
                  and have worked alongside <a href="https://ajyl.github.io/about">Dr. Andrew Lee</a> and <a
                    href="https://web.eecs.umich.edu/~mihalcea/">Prof. Rada Mihalcea</a> to leverage interpretability to study
                  toxicity and personas in LLMs.
                  </p>

                  <p>
                    Last summer and fall, I interned with the <a href="https://www.kasl.ai/">Krueger AI Safety Lab</a> at the
                    University of Cambridge working alongside <a href="https://davidscottkrueger.com/">Prof. David Krueger</a>, <a
                      href="https://ekdeepslubana.github.io/">Dr. Ekdeep Singh Lubana</a>, and <a
                      href="https://x.com/LauraRuis">Laura Ruis</a> to develop new inference-time methods for model
                    behavioral control.
                    
                  </p>

                  <p>
                    I have also worked with <a href="https://sites.google.com/view/htanaka/home">Hidenori Tanaka</a> at
                    the <a href="https://cbs.fas.harvard.edu/">Harvard Center for Brain Science</a> to mechanistically study in-context
                    learning.
                  </p>


                  <p>
                    I first started doing interpretability research with <a href="https://www.neelnanda.io/about">Neel Nanda</a> through the <a
                      href="https://www.matsprogram.org/">ML Alignment & Theory Scholars</a> Program.
                  </p>


                  <!-- Stuff -->
                  <p style="text-align:center">
                    <a href="mailto:presi@umich.edu">Email</a> &nbsp/&nbsp
                    <a href="data/Resume_PhD.pdf">CV</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=FuETqOUAAAAJ&hl=en">Google Scholar</a>
                  </p>
                </td>

                <!-- Front image -->
                <td style="padding:2.5%;width:40%;max-width:40%;text-align: left">
                  <a href="images/headshot.png"><img style="width:100%;max-width:100%;display: block" alt="profile photo"
                      src="images/headshot.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>



          <!-- Publications -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Publications (* denotes equal contribution)</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/comp.png" alt="Comp Dynamics" width="160" style="border-style: none">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2412.01003">
                    <papertitle>Competition Dynamics Shape Algorithmic Phases of In-Context Learning</papertitle>
                  </a>
                  <br>
                  <a>Core Francisco Park</a>,
                  <a>Ekdeep Singh Lubana</a>,
                  <strong>Itamar Pres</strong>,
                  and
                  <a>Hidenori Tanaka</a>
                  <br>
                  <em>ICLR</em>, 2025 <font color="red"> (Spotlight)</font>
                  <br>
              
              
                  <p> 
                    We introduce a framework for understanding in-context learning (ICL) using a synthetic task based on Markov chain
                    mixtures. We find this task replicates most of the previously described ICL phenomena. We identify four distinct algorithmic phases, blending unigram or bigram statistics with fuzzy retrieval or inference.
                    These phases compete dynamically, revealing sharp transitions in ICL behavior due to changes in training conditions,
                    such as data diversity and context size. I’m proud to have led the interpretability work,
                    quantifying neuron memorization and tracking attention head evolution during training—check it out!
          
                  </p>
                </td>
              </tr>
              


              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/benchmark.png" alt="CAA Benchmark" width="160" style="border-style: none">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2410.17245">
                    <papertitle>Towards Reliable Evaluation of Behavior Steering Interventions in LLMs</papertitle>
                  </a>
                  <br>
                  <strong>Itamar Pres</strong>,
                  <a>Laura Ruis</a>,
                  <a>Ekdeep Singh Lubana</a>,
                  and
                  <a>David Krueger</a>
                  
                  <br>
                  <em>NeurIPS workshop on Foundation Model Interventions</em>, 2024 <font color="red"> (Spotlight)</font>
                  <br>
              
              
                  <p>
                  We propose a robust evaluation pipeline for behavioral steering interventions in LLMs, addressing gaps in current
                  methods like subjective metrics and lack of comparability. Our pipeline aligns with downstream tasks, considers model
                  likelihoods, enables cross-behavioral comparisons, and includes baselines. Testing interventions like Contrastive
                  Activation Addition (CAA) and Inference-Time Intervention (ITI), we find their efficacy varies by behavior, with results
                  often overstated and critical distinctions between promoting and suppressing behaviors overlooked.
                  </p>
                </td>
              </tr>


              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/toxicity.png" alt="Toxicity DPO" width="160" style="border-style: none">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2401.01967">
                    <papertitle>A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity</papertitle>
                  </a>
                  <br>
                  <a>Andrew Lee</a>,
                  <a>Xiaoyan Bai</a>,
                  <strong>Itamar Pres</strong>,
                  <a>Martin Wattenberg</a>,
                  <a>Jonathan K. Kummerfeld</a>,
                  and
                  <a>Rada Mihalcea</a>
                  <br>
                  <em>ICML</em>, 2024 <font color="red"> (Oral)</font>
                  <br>
              
              
                  <p>
                    We study a popular algorithm, direct preference optimization (DPO), and the mechanisms by which it reduces
                    toxicity. We first study how toxicity is represented and elicited in pre-trained language
                    models (GPT2-medium, Llama2-7b). We then apply DPO to reduce toxicity and find that capabilities learned from
                    pre-training are not removed,
                    but rather bypassed. We use this insight to demonstrate a simple method to un-align the models,
                    reverting them back to their toxic behavior.
              
                  </p>
                </td>
              </tr>


          



              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:0px">
                      <br>
                      <p style="text-align:right;font-size:small;">
                        Website template source available <a
                          href="https://github.com/jonbarron/jonbarron_website">here</a>.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>
        </td>
      </tr>
  </table>
</body>

</html>